{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6:  Train Various Regression Models and Compare Their Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will train various regression models (regressors) and compare their performances. You will train, test and evaluate individual models as well as ensemble models. You will:\n",
    "\n",
    "1. Build your DataFrame and define your ML problem:\n",
    "    * Load the Airbnb \"listings\" data set\n",
    "    * Define the label - what are you predicting?\n",
    "    * Identify the features\n",
    "2. Create labeled examples from the data set.\n",
    "3. Split the data into training and test data sets.\n",
    "4. Train, test and evaluate two individual regressors.\n",
    "5. Use the stacking ensemble method to train the same regressors.\n",
    "6. Train, test and evaluate Gradient Boosted Decision Trees.\n",
    "7. Train, test and evaluate Random Forest.\n",
    "8. Visualize and compare the performance of all of the models.\n",
    "\n",
    "<font color='red'><b>Note:</font><br> \n",
    "<font color='red'><b>1. Some of the code cells in this notebook may take a while to run.</font><br>\n",
    "<font color='red'><b>2. Ignore warning messages that pertain to deprecated packages.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Build Your DataFrame and Define Your ML Problem\n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "We will work with the data set ``airbnbData_train``. This data set already has all the necessary preprocessing steps implemented, including one-hot encoding of the categorical variables, scaling of all numerical variable values, and imputing missing values. It is ready for modeling.\n",
    "\n",
    "<b>Task</b>: In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`.\n",
    "\n",
    "You will be working with the file named \"airbnbData_train.csv\" that is located in a folder named \"data_regressors\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28022, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>has_availability</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_total_listings_count</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>...</th>\n",
       "      <th>n_host_verifications</th>\n",
       "      <th>neighbourhood_group_cleansed_Bronx</th>\n",
       "      <th>neighbourhood_group_cleansed_Brooklyn</th>\n",
       "      <th>neighbourhood_group_cleansed_Manhattan</th>\n",
       "      <th>neighbourhood_group_cleansed_Queens</th>\n",
       "      <th>neighbourhood_group_cleansed_Staten Island</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Hotel room</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.578829</td>\n",
       "      <td>-2.845589</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>-0.054298</td>\n",
       "      <td>-1.007673</td>\n",
       "      <td>...</td>\n",
       "      <td>1.888373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-4.685756</td>\n",
       "      <td>-0.430024</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>-2.473964</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.605041</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.069535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>1.010024</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.470102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.576550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.054002</td>\n",
       "      <td>-0.066308</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-1.007673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>1.010024</td>\n",
       "      <td>-0.095716</td>\n",
       "      <td>-0.095716</td>\n",
       "      <td>-0.470102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>1.010024</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.067470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.902404</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>1.010024</td>\n",
       "      <td>-0.095716</td>\n",
       "      <td>-0.095716</td>\n",
       "      <td>-1.007673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>-3.635293</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>-0.104000</td>\n",
       "      <td>-1.007673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578052</td>\n",
       "      <td>0.963571</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>-0.112284</td>\n",
       "      <td>0.605041</td>\n",
       "      <td>...</td>\n",
       "      <td>1.395388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_is_superhost  host_has_profile_pic  host_identity_verified  \\\n",
       "0              False                  True                    True   \n",
       "1              False                  True                    True   \n",
       "2              False                  True                    True   \n",
       "3              False                  True                   False   \n",
       "4              False                  True                    True   \n",
       "5               True                  True                    True   \n",
       "6              False                  True                    True   \n",
       "7              False                  True                    True   \n",
       "8              False                  True                    True   \n",
       "9               True                  True                    True   \n",
       "\n",
       "   has_availability  instant_bookable  host_response_rate  \\\n",
       "0              True             False           -0.578829   \n",
       "1              True             False           -4.685756   \n",
       "2              True             False            0.578052   \n",
       "3              True             False            0.578052   \n",
       "4              True             False           -0.054002   \n",
       "5              True             False            0.578052   \n",
       "6              True              True            0.578052   \n",
       "7              True              True            0.578052   \n",
       "8              True             False            0.578052   \n",
       "9              True              True            0.578052   \n",
       "\n",
       "   host_acceptance_rate  host_listings_count  host_total_listings_count  \\\n",
       "0             -2.845589            -0.054298                  -0.054298   \n",
       "1             -0.430024            -0.112284                  -0.112284   \n",
       "2             -2.473964            -0.112284                  -0.112284   \n",
       "3              1.010024            -0.112284                  -0.112284   \n",
       "4             -0.066308            -0.112284                  -0.112284   \n",
       "5              1.010024            -0.095716                  -0.095716   \n",
       "6              1.010024            -0.112284                  -0.112284   \n",
       "7              1.010024            -0.095716                  -0.095716   \n",
       "8             -3.635293            -0.104000                  -0.104000   \n",
       "9              0.963571            -0.112284                  -0.112284   \n",
       "\n",
       "   accommodates  ...  n_host_verifications  \\\n",
       "0     -1.007673  ...              1.888373   \n",
       "1      0.067470  ...              0.409419   \n",
       "2      0.605041  ...             -1.069535   \n",
       "3     -0.470102  ...             -0.576550   \n",
       "4     -1.007673  ...              0.902404   \n",
       "5     -0.470102  ...              0.902404   \n",
       "6      0.067470  ...              0.902404   \n",
       "7     -1.007673  ...             -0.083566   \n",
       "8     -1.007673  ...             -0.083566   \n",
       "9      0.605041  ...              1.395388   \n",
       "\n",
       "   neighbourhood_group_cleansed_Bronx  neighbourhood_group_cleansed_Brooklyn  \\\n",
       "0                                 0.0                                    0.0   \n",
       "1                                 0.0                                    1.0   \n",
       "2                                 0.0                                    1.0   \n",
       "3                                 0.0                                    0.0   \n",
       "4                                 0.0                                    0.0   \n",
       "5                                 0.0                                    1.0   \n",
       "6                                 0.0                                    1.0   \n",
       "7                                 0.0                                    0.0   \n",
       "8                                 0.0                                    1.0   \n",
       "9                                 0.0                                    1.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Manhattan  \\\n",
       "0                                     1.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     1.0   \n",
       "4                                     1.0   \n",
       "5                                     0.0   \n",
       "6                                     0.0   \n",
       "7                                     1.0   \n",
       "8                                     0.0   \n",
       "9                                     0.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Queens  \\\n",
       "0                                  0.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "5                                  0.0   \n",
       "6                                  0.0   \n",
       "7                                  0.0   \n",
       "8                                  0.0   \n",
       "9                                  0.0   \n",
       "\n",
       "   neighbourhood_group_cleansed_Staten Island  room_type_Entire home/apt  \\\n",
       "0                                         0.0                        1.0   \n",
       "1                                         0.0                        1.0   \n",
       "2                                         0.0                        1.0   \n",
       "3                                         0.0                        0.0   \n",
       "4                                         0.0                        0.0   \n",
       "5                                         0.0                        0.0   \n",
       "6                                         0.0                        1.0   \n",
       "7                                         0.0                        0.0   \n",
       "8                                         0.0                        0.0   \n",
       "9                                         0.0                        1.0   \n",
       "\n",
       "   room_type_Hotel room  room_type_Private room  room_type_Shared room  \n",
       "0                   0.0                     0.0                    0.0  \n",
       "1                   0.0                     0.0                    0.0  \n",
       "2                   0.0                     0.0                    0.0  \n",
       "3                   0.0                     1.0                    0.0  \n",
       "4                   0.0                     1.0                    0.0  \n",
       "5                   0.0                     1.0                    0.0  \n",
       "6                   0.0                     0.0                    0.0  \n",
       "7                   0.0                     1.0                    0.0  \n",
       "8                   0.0                     1.0                    0.0  \n",
       "9                   0.0                     0.0                    0.0  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "file = os.path.join(os.getcwd(), \"data_regressors\", \"airbnbData_train.csv\")\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the Label\n",
    "\n",
    "Your goal is to train a machine learning model that predicts the price of an Airbnb listing. This is an example of supervised learning and is a regression problem. In our dataset, our label will be the `price` column and the label contains continuous values.\n",
    "\n",
    "#### Evaluation Metrics for Regressors\n",
    "\n",
    "So far, we have mostly focused on classification problems. For this assignment, we will focus on a regression problem and predict a continuous outcome. There are different evaluation metrics that are used to determine the performance of a regressor. We will use two metrics to evaluate our regressors: RMSE (root mean square error) and $R^2$ (coefficient of determination).\n",
    "\n",
    "RMSE:<br>\n",
    "RMSE finds the average difference between the predicted values and the actual values. We will compute the RMSE on the test set.  To compute the RMSE, we will use the scikit-learn ```mean_squared_error()``` function. Since RMSE finds the difference between the predicted and actual values, lower RMSE values indicate good performance - the model fits the data well and makes more accurate predictions. On the other hand, higher RSME values indicate that the model is not performing well.\n",
    "\n",
    "$R^2$:<br>\n",
    "$R^2$ is a measure of the proportion of variability in the prediction that the model was able to make using the test data. An $R^2$ value of 1 is perfect and 0 implies no explanatory value. We can use scikit-learn's ```r2_score()``` function to compute it. Since $R^2$ measures how well the model fits the data, a higher $R^2$ value indicates that good performance and a lower $R^2$ indicates that poor performance.\n",
    "\n",
    "#### Identify Features\n",
    "\n",
    "Our features will be all of the remaining columns in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Create Labeled Examples from the Data Set \n",
    "\n",
    "<b>Task</b>: In the code cell below, create labeled examples from DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28022, 49) (28022,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "host_is_superhost                                  bool\n",
       "host_has_profile_pic                               bool\n",
       "host_identity_verified                             bool\n",
       "has_availability                                   bool\n",
       "instant_bookable                                   bool\n",
       "host_response_rate                              float64\n",
       "host_acceptance_rate                            float64\n",
       "host_listings_count                             float64\n",
       "host_total_listings_count                       float64\n",
       "accommodates                                    float64\n",
       "bathrooms                                       float64\n",
       "bedrooms                                        float64\n",
       "beds                                            float64\n",
       "price                                           float64\n",
       "minimum_nights                                  float64\n",
       "maximum_nights                                  float64\n",
       "minimum_minimum_nights                          float64\n",
       "maximum_minimum_nights                          float64\n",
       "minimum_maximum_nights                          float64\n",
       "maximum_maximum_nights                          float64\n",
       "minimum_nights_avg_ntm                          float64\n",
       "maximum_nights_avg_ntm                          float64\n",
       "availability_30                                 float64\n",
       "availability_60                                 float64\n",
       "availability_90                                 float64\n",
       "availability_365                                float64\n",
       "number_of_reviews                               float64\n",
       "number_of_reviews_ltm                           float64\n",
       "number_of_reviews_l30d                          float64\n",
       "review_scores_rating                            float64\n",
       "review_scores_cleanliness                       float64\n",
       "review_scores_checkin                           float64\n",
       "review_scores_communication                     float64\n",
       "review_scores_location                          float64\n",
       "review_scores_value                             float64\n",
       "calculated_host_listings_count                  float64\n",
       "calculated_host_listings_count_entire_homes     float64\n",
       "calculated_host_listings_count_private_rooms    float64\n",
       "calculated_host_listings_count_shared_rooms     float64\n",
       "reviews_per_month                               float64\n",
       "n_host_verifications                            float64\n",
       "neighbourhood_group_cleansed_Bronx              float64\n",
       "neighbourhood_group_cleansed_Brooklyn           float64\n",
       "neighbourhood_group_cleansed_Manhattan          float64\n",
       "neighbourhood_group_cleansed_Queens             float64\n",
       "neighbourhood_group_cleansed_Staten Island      float64\n",
       "room_type_Entire home/apt                       float64\n",
       "room_type_Hotel room                            float64\n",
       "room_type_Private room                          float64\n",
       "room_type_Shared room                           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X = df.drop(['price'], axis = 1)\n",
    "y = df['price']\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "df.isnull().sum()\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Create Training and Test Data Sets\n",
    "\n",
    "<b>Task</b>: In the code cell below, create training and test sets out of the labeled examples. Create a test set that is 30 percent of the size of the data set. Save the results to variables `X_train, X_test, y_train, y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19615, 49) (8407, 49) (19615,) (8407,)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Train, Test and Evaluate Two Regression Models: Linear Regression and Decision Tree\n",
    "\n",
    "### a. Train, Test and Evaluate a Linear Regression\n",
    "\n",
    "You will use the scikit-learn `LinearRegression` class to create a linear regression model. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "First let's import `LinearRegression`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: Initialize a scikit-learn `LinearRegression` model object with no arguments, and fit the model to the training data. The model object should be named `lr_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "lr_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Test your model on the test set (`X_test`). Call the ``predict()`` method  to use the fitted model to generate a vector of predictions on the test set. Save the result to the variable ``y_lr_pred``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31668091, -0.24261475, -0.29226685, ...,  0.86761475,\n",
       "       -0.30657959,  0.52697754])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call predict() to use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_lr_pred = lr_model.predict(X_test)\n",
    "y_lr_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the RMSE, we will use the scikit-learn ```mean_squared_error()``` function, which computes the mean squared error between the predicted values and the actual values: ```y_lr_pred``` and```y_test```. In order to obtain the root mean squared error, we will specify the parameter `squared=False`. \n",
    "\n",
    "To compute the $R^2$, we will use the scikit-learn ```r2_score()``` function. \n",
    "\n",
    "<b>Task</b>: In the code cell below, do the following:\n",
    "\n",
    "1. Call the `mean_squared_error()` function with arguments `y_test` and `y_lr_pred` and the parameter `squared=False` to find the RMSE. Save your result to the variable `lr_rmse`.\n",
    "\n",
    "2. Call the `r2_score()` function with the arguments `y_test` and `y_lr_pred`.  Save the result to the variable `lr_r2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LR] Root Mean Squared Error: 0.790521096352486\n",
      "[LR] R2: 0.40195004191049066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "lr_rmse = mean_squared_error(y_test, y_lr_pred, squared=False)\n",
    "\n",
    "# 2. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "lr_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[LR] Root Mean Squared Error: {0}'.format(lr_rmse))\n",
    "print('[LR] R2: {0}'.format(lr_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Train, Test and Evaluate a Decision Tree Using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the scikit-learn `DecisionTreeRegressor` class to create a decision tree regressor. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html).\n",
    "\n",
    "First let's import `DecisionTreeRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Up a Parameter Grid \n",
    "\n",
    "<b>Task</b>: Create a dictionary called `param_grid` that contains possible hyperparameter values for `max_depth` and `min_samples_leaf`. The dictionary should contain the following key/value pairs:\n",
    "\n",
    "* a key called 'max_depth' with a value which is a list consisting of the integers 4 and 8\n",
    "* a key called 'min_samples_leaf' with a value which is a list consisting of the integers 25 and 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': [4, 8], 'min_samples_leaf': [25, 50]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "param_grid = {'max_depth': [4,8], 'min_samples_leaf': [25, 50]}\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use `GridSearchCV` to fit a grid of decision tree regressors and search over the different values of hyperparameters `max_depth` and `min_samples_leaf` to find the ones that results in the best 3-fold cross-validation (CV) score.\n",
    "\n",
    "\n",
    "You will pass the following arguments to `GridSearchCV()`:\n",
    "\n",
    "1. A decision tree **regressor** model object.\n",
    "2. The `param_grid` variable.\n",
    "3. The number of folds (`cv=3`).\n",
    "4. The scoring method `scoring='neg_root_mean_squared_error'`. Note that `neg_root_mean_squared_error` returns the negative RMSE.\n",
    "\n",
    "\n",
    "Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Create a DecisionTreeRegressor model object without supplying arguments. \n",
    "#    Save the model object to the variable 'dt_regressor'\n",
    "\n",
    "dt_regressor = DecisionTreeRegressor()\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 2. Run a Grid Search with 3-fold cross-validation and assign the output to the object 'dt_grid'.\n",
    "#    * Pass the model and the parameter grid to GridSearchCV()\n",
    "#    * Set the number of folds to 3\n",
    "#    * Specify the scoring method\n",
    "\n",
    "dt_grid = GridSearchCV(dt_regressor, param_grid, cv = 3, scoring='neg_root_mean_squared_error')\n",
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# 3. Fit the model (use the 'grid' variable) on the training data and assign the fitted model to the \n",
    "#    variable 'dt_grid_search'\n",
    "\n",
    "dt_grid_search = dt_grid.fit(X_train, y_train)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below prints the RMSE score of the best model using the `best_score_` attribute of the fitted grid search object `dt_grid_search`. Note that specifying a scoring method of `neg_root_mean_squared_error` will result in the negative RMSE, so we will multiply `dt_grid_search.best_score` by -1 to obtain the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] RMSE for the best model is : 0.71\n"
     ]
    }
   ],
   "source": [
    "rmse_DT = -1 * dt_grid_search.best_score_\n",
    "print(\"[DT] RMSE for the best model is : {:.2f}\".format(rmse_DT) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, obtain the best model hyperparameters identified by the grid search and save them to the variable `dt_best_params`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 8, 'min_samples_leaf': 25}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best_params = dt_grid_search.best_params_\n",
    "# YOUR CODE HERE\n",
    "\n",
    "dt_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: In the code cell below, initialize a `DecisionTreeRegressor` model object, supplying the best values of hyperparameters `max_depth` and `min_samples_leaf` as arguments.  Name the model object `dt_model`. Then fit the model `dt_model` to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dt_model = DecisionTreeRegressor(max_depth = 8, min_samples_leaf = 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Test your model `dt_model` on the test set `X_test`. Call the ``predict()`` method  to use the fitted model to generate a vector of predictions on the test set. Save the result to the variable ``y_dt_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `dt_rmse` and `dt_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DT] Root Mean Squared Error: 0.790521096352486\n",
      "[DT] R2: 0.40195004191049066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_dt_pred = dt_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE using mean_squared_error()\n",
    "# YOUR CODE HERE\n",
    "dt_rmse = mean_squared_error(y_test, y_lr_pred, squared=False)\n",
    "\n",
    "# 3. Compute the R2 score using r2_score()\n",
    "# YOUR CODE HERE\n",
    "dt_r2 = r2_score(y_test, y_lr_pred)\n",
    "\n",
    "print('[DT] Root Mean Squared Error: {0}'.format(dt_rmse))\n",
    "print('[DT] R2: {0}'.format(dt_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Train, Test and Evaluate Ensemble Models: Stacking "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the stacking ensemble method to train two regression models. You will use the scikit-learn `StackingRegressor` class. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html).\n",
    "\n",
    "First let's import `StackingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the assignment, we will use two models jointly. In the code cell below, we creates a list of tuples, each consisting of a scikit-learn model function and the corresponding shorthand name that we choose. We will specify the hyperparameters for the decision tree that we determined through the grid search above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(\"DT\", DecisionTreeRegressor(max_depth=8, min_samples_leaf=25)),\n",
    "              (\"LR\", LinearRegression())\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task</b>: \n",
    "\n",
    "\n",
    "1. Create a `StackingRegressor` model object. Call `StackingRegressor()` with the following parameters:\n",
    "    * Assign the list `estimators` to the parameter `estimators`.\n",
    "    * Use the parameter 'passthrough=False'. \n",
    "Assign the results to the variable `stacking_model`.\n",
    "\n",
    "2. Fit `stacking_model` to the training data.\n",
    "\n",
    "As you read up on the definition of the `StackingRegressor` class, you will notice that by default, the results of each model are combined using a ridge regression (a \"final regressor\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implement Stacking...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Implement Stacking...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "stacking_model = StackingRegressor(estimators = estimators, passthrough = False)\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your ensemble model `stacking_model` on the test set (`X_test`). Save the result to the variable `stacking_pred`. Evaluate the results by computing the RMSE and R2 score. Save the results to the variables `stack_rmse` and `stack_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 0.7201125589224513\n",
      "R2: 0.5037376747936761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "stacking_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE \n",
    "# YOUR CODE HERE\n",
    "stack_rmse = mean_squared_error(y_test, stacking_pred, squared = False)\n",
    "\n",
    "# 3. Compute the R2 score\n",
    "# YOUR CODE HERE\n",
    "stack_r2 = r2_score(y_test, stacking_pred)\n",
    "   \n",
    "print('Root Mean Squared Error: {0}'.format(stack_rmse))\n",
    "print('R2: {0}'.format(stack_r2))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Train, Test and Evaluate  Evaluate Ensemble Models: Gradient Boosted Decision Trees \n",
    "\n",
    "You will use the scikit-learn `GradientBoostingRegressor` class to create a gradient boosted decision tree. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html).\n",
    "\n",
    "First let's import `GradientBoostingRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you already performed a grid search to find the best model hyperparameters for your gradient boosted decision tree. (We are omitting this step to save computation time.) The best values are: `max_depth=2`, and `n_estimators = 300`. \n",
    "\n",
    "<b>Task</b>: Initialize a `GradientBoostingRegressor` model object with the above values as arguments. Save the result to the variable `gbdt_model`. Fit the `gbdt_model` model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin GBDT Implementation...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Begin GBDT Implementation...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "gbdt_model = GradientBoostingRegressor(max_depth = 2, n_estimators = 300)\n",
    "gbdt_model.fit(X_train, y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your model `gbdt_model` on the test set `X_test`. Save the result to the variable ``y_gbdt_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `gbdt_rmse` and `gbdt_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GBDT] Root Mean Squared Error: 0.6795402355889928\n",
      "[GBDT] R2: 0.5580828169544229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_gbdt_pred = gbdt_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE \n",
    "# YOUR CODE HERE\n",
    "gbdt_rmse = mean_squared_error(y_test, y_gbdt_pred, squared = False)\n",
    "\n",
    "# 3. Compute the R2 score \n",
    "# YOUR CODE HERE\n",
    "gbdt_r2 = r2_score(y_test, y_gbdt_pred)\n",
    "\n",
    "print('[GBDT] Root Mean Squared Error: {0}'.format(gbdt_rmse))\n",
    "print('[GBDT] R2: {0}'.format(gbdt_r2))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Train, Test and Evaluate  Ensemble Models: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the scikit-learn `RandomForestRegressor` class to create a gradient boosted decision tree. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html).\n",
    "\n",
    "First let's import `RandomForestRegressor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume you already performed a grid search to find the best model hyperparameters for your random forest model. (We are omitting this step to save computation time.) The best values are: `max_depth=32`, and `n_estimators = 300`. \n",
    "\n",
    "<b>Task</b>: Initialize a `RandomForestRegressor` model object with the above values as arguments. Save the result to the variable `rf_model`. Fit the `rf_model` model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin RF Implementation...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "print('Begin RF Implementation...')\n",
    "\n",
    "# YOUR CODE HERE\n",
    "rf_model = RandomForestRegressor(max_depth = 32, n_estimators = 300)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print('End')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the `predict()` method to test your model `rf_model` on the test set `X_test`. Save the result to the variable ``y_rf_pred``. Evaluate the results by computing the RMSE and R2 score in the same manner as you did above. Save the results to the variables `rf_rmse` and `rf_r2`.\n",
    "\n",
    "Complete the code in the cell below to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RF] Root Mean Squared Error: 0.6394658406357898\n",
      "[RF] R2: 0.608668114161584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Use the fitted model to make predictions on the test data\n",
    "# YOUR CODE HERE\n",
    "y_rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# 2. Compute the RMSE \n",
    "# YOUR CODE HERE\n",
    "rf_rmse = mean_squared_error(y_test, y_rf_pred, squared = False)\n",
    "\n",
    "# 3. Compute the R2 score \n",
    "# YOUR CODE HERE\n",
    "rf_r2 = r2_score(y_test, y_rf_pred)\n",
    "\n",
    "print('[RF] Root Mean Squared Error: {0}'.format(rf_rmse))\n",
    "print('[RF] R2: {0}'.format(rf_r2))                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Visualize and Compare Model Performance\n",
    "\n",
    "The code cell below will plot the RMSE and R2 score for each regressor. \n",
    "\n",
    "<b>Task:</b> Complete the code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RMSE_Results = [stack_rmse, lr_rmse, dt_rmse, gbdt_rmse, rf_rmse]\n",
    "R2_Results = [stack_r2, lr_r2, dt_r2, gbdt_r2, rf_r2]\n",
    "\n",
    "rg= np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "# 1. Create bar plot with RMSE results\n",
    "# YOUR CODE HERE\n",
    "plt.bar(rg, RMSE_Results, width, label='RMSE', color='blue')\n",
    "\n",
    "# 2. Create bar plot with R2 results\n",
    "# YOUR CODE HERE\n",
    "plt.bar(rg, R2_Results, width, label='R2', color='green')\n",
    "\n",
    "labels = ['Stacking','LR', 'DT', 'GBDT', 'RF']\n",
    "plt.xticks(rg + width/2, labels)\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"RMSE/R2\")\n",
    "\n",
    "\n",
    "plt.ylim([0,1])\n",
    "plt.title('Model Performance')\n",
    "plt.legend(loc='upper left', ncol=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Analysis</b>: Compare and contrast the resulting $R^2$ and RSME scores of the ensemble models and the individual models. Are the ensemble models performing better? Which is the best performing model? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the ensemble models like Stacking, GBDT, and RF are performing much better especially in increasing variance with R2 scores than just the LR or DT models. \n",
    "The best performing model is RF since it has the lowest score for RMSE, and the highest score for R squared."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
